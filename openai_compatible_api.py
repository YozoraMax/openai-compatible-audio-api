#!/usr/bin/env python3
"""
OpenAI-compatible API server for CosyVoice (TTS) and Dolphin (ASR)
Provides /v1/audio/speech and /v1/audio/transcriptions endpoints
"""

import sys
import os
import io
import base64
import tempfile
import traceback
from pathlib import Path
from typing import Optional, List

import torch
import torchaudio
import numpy as np
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import Response
from pydantic import BaseModel
import uvicorn

# Add CosyVoice to path
sys.path.append(str(Path(__file__).parent / "CosyVoice" / "third_party" / "Matcha-TTS"))
sys.path.append(str(Path(__file__).parent / "CosyVoice"))

# Add Dolphin to path  
sys.path.append(str(Path(__file__).parent / "Dolphin"))

# Import CosyVoice
try:
    from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
    from cosyvoice.utils.file_utils import load_wav
except ImportError as e:
    print(f"Failed to import CosyVoice: {e}")
    CosyVoice = None
    CosyVoice2 = None

# Import Dolphin
try:
    sys.path.append(str(Path(__file__).parent / "Dolphin"))
    import dolphin
except ImportError as e:
    print(f"Failed to import Dolphin: {e}")
    dolphin = None

app = FastAPI(title="OpenAI Compatible Audio API", version="1.0.0")

# Global models
cosyvoice_model = None
dolphin_model = None

def fix_cosyvoice_model_path(expected_model_path: str = "CosyVoice/pretrained_models/CosyVoice2-0.5B"):
    """ä¿®å¤CosyVoiceæ¨¡åž‹è·¯å¾„é—®é¢˜"""
    base_dir = Path(__file__).parent

    # APIæœŸæœ›çš„è·¯å¾„
    expected_path = base_dir / expected_model_path

    # å¦‚æžœæœŸæœ›è·¯å¾„å·²å­˜åœ¨ä¸”æœ‰æ•ˆï¼Œç›´æŽ¥è¿”å›ž
    if expected_path.exists():
        config_files = list(expected_path.glob("*.yaml"))
        if config_files:
            print(f"âœ“ CosyVoiceæ¨¡åž‹è·¯å¾„æ­£ç¡®: {expected_model_path}")
            return True

    # æ£€æŸ¥ModelScopeä¸‹è½½çš„å®žé™…è·¯å¾„
    potential_paths = [
        base_dir / "CosyVoice" / "pretrained_models" / "iic" / "CosyVoice2-0.5B",
        base_dir / "models" / "cosyvoice" / "iic" / "CosyVoice2-0.5B",
        base_dir / "CosyVoice" / "pretrained_models" / "CosyVoice-300M-SFT",
        base_dir / "CosyVoice" / "pretrained_models" / "CosyVoice-300M",
    ]

    for actual_path in potential_paths:
        if actual_path.exists() and actual_path.is_dir():
            # æ£€æŸ¥æ˜¯å¦æœ‰é…ç½®æ–‡ä»¶
            config_files = list(actual_path.glob("*.yaml"))
            if config_files:
                print(f"æ‰¾åˆ°CosyVoiceæ¨¡åž‹: {actual_path}")
                print(f"é…ç½®æ–‡ä»¶: {[f.name for f in config_files]}")

                # ç¡®ä¿æœŸæœ›è·¯å¾„çš„çˆ¶ç›®å½•å­˜åœ¨
                expected_path.parent.mkdir(parents=True, exist_ok=True)

                # å°è¯•åˆ›å»ºç¬¦å·é“¾æŽ¥
                if not expected_path.exists():
                    try:
                        expected_path.symlink_to(actual_path, target_is_directory=True)
                        print(f"âœ“ åˆ›å»ºç¬¦å·é“¾æŽ¥: {expected_path} -> {actual_path}")
                        return True
                    except OSError:
                        # å¦‚æžœç¬¦å·é“¾æŽ¥å¤±è´¥ï¼Œå°è¯•ç§»åŠ¨
                        try:
                            import shutil
                            if expected_path.exists():
                                shutil.rmtree(expected_path)
                            shutil.move(str(actual_path), str(expected_path))
                            print(f"âœ“ ç§»åŠ¨æ¨¡åž‹æ–‡ä»¶: {actual_path} -> {expected_path}")
                            return True
                        except Exception as e:
                            print(f"âœ— ç§»åŠ¨æ¨¡åž‹å¤±è´¥: {e}")
                            continue
                else:
                    return True

    return False

def check_and_download_models(cosyvoice_model_path: str = "CosyVoice/pretrained_models/CosyVoice2-0.5B"):
    """æ£€æŸ¥å¹¶ä¸‹è½½å¿…è¦çš„æ¨¡åž‹"""
    print("æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶...")

    # æ£€æŸ¥å¹¶ä¿®å¤CosyVoiceæ¨¡åž‹è·¯å¾„
    cosyvoice_ready = fix_cosyvoice_model_path(cosyvoice_model_path)

    if not cosyvoice_ready:
        print(f"âœ— CosyVoiceæ¨¡åž‹ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½åˆ°: {cosyvoice_model_path}")
        try:
            download_cosyvoice_model(cosyvoice_model_path)
            # ä¸‹è½½åŽå†æ¬¡å°è¯•ä¿®å¤è·¯å¾„
            cosyvoice_ready = fix_cosyvoice_model_path(cosyvoice_model_path)
        except Exception as e:
            print(f"CosyVoiceæ¨¡åž‹ä¸‹è½½å¤±è´¥: {e}")
            cosyvoice_ready = False

    # æ£€æŸ¥Dolphinæ¨¡åž‹ï¼ˆä½¿ç”¨FunASRï¼‰
    dolphin_ready = False
    try:
        from funasr import AutoModel
        # ç®€å•æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆå§‹åŒ–æ¨¡åž‹ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
        print("æ£€æŸ¥Dolphin/FunASRæ¨¡åž‹...")
        model_dir = Path(__file__).parent / "models" / "dolphin"
        model_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®ç¼“å­˜ç›®å½•
        os.environ['FUNASR_CACHE_HOME'] = str(model_dir)

        # å°è¯•åŠ è½½æ¨¡åž‹ï¼ˆå¦‚æžœä¸å­˜åœ¨ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
        print("åˆå§‹åŒ–FunASRæ¨¡åž‹ï¼ˆå¦‚éœ€è¦ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰...")
        test_model = AutoModel(model="paraformer-zh", cache_dir=str(model_dir))
        print("âœ“ Dolphin/FunASRæ¨¡åž‹å‡†å¤‡å°±ç»ª")
        dolphin_ready = True

    except ImportError:
        print("âœ— FunASRæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install funasr")
    except Exception as e:
        print(f"âœ— Dolphin/FunASRæ¨¡åž‹åˆå§‹åŒ–å¤±è´¥: {e}")

    return cosyvoice_ready, dolphin_ready

def download_cosyvoice_model(model_path: str):
    """ä¸‹è½½CosyVoiceæ¨¡åž‹"""
    try:
        from modelscope import snapshot_download

        # åˆ›å»ºæ¨¡åž‹ç›®å½•
        full_path = Path(__file__).parent / model_path
        full_path.parent.mkdir(parents=True, exist_ok=True)

        print("ä»ŽModelScopeä¸‹è½½CosyVoiceæ¨¡åž‹...")
        downloaded_path = snapshot_download(
            'iic/CosyVoice2-0.5B',
            cache_dir=str(full_path.parent)
        )
        print(f"âœ“ CosyVoiceæ¨¡åž‹ä¸‹è½½å®Œæˆ: {downloaded_path}")

        # ä¸‹è½½å®ŒæˆåŽï¼Œè°ƒç”¨è·¯å¾„ä¿®å¤å‡½æ•°
        fix_cosyvoice_model_path(model_path)

        return downloaded_path

    except ImportError:
        print("âœ— ModelScopeæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install modelscope")
        raise RuntimeError("æ— æ³•ä¸‹è½½CosyVoiceæ¨¡åž‹ï¼ŒModelScopeæœªå®‰è£…")
    except Exception as e:
        print(f"âœ— CosyVoiceæ¨¡åž‹ä¸‹è½½å¤±è´¥: {e}")
        raise RuntimeError(f"CosyVoiceæ¨¡åž‹ä¸‹è½½å¤±è´¥: {e}")

class TTSRequest(BaseModel):
    model: str = "tts-1"
    input: str
    voice: str = "alloy"
    response_format: str = "mp3"
    speed: float = 1.0

class TranscriptionResponse(BaseModel):
    text: str

def initialize_cosyvoice(model_path: str = "CosyVoice/pretrained_models/CosyVoice2-0.5B"):
    """Initialize CosyVoice model"""
    global cosyvoice_model

    if not CosyVoice or not CosyVoice2:
        raise RuntimeError("CosyVoice not available")

    full_path = Path(__file__).parent / model_path
    if not full_path.exists():
        # Try alternative paths including the downloaded ModelScope path
        alt_paths = [
            "CosyVoice/pretrained_models/iic/CosyVoice2-0.5B",  # ModelScopeä¸‹è½½è·¯å¾„
            "CosyVoice/pretrained_models/CosyVoice-300M-SFT",
            "CosyVoice/pretrained_models/CosyVoice-300M",
        ]
        for alt_path in alt_paths:
            alt_full_path = Path(__file__).parent / alt_path
            if alt_full_path.exists():
                full_path = alt_full_path
                print(f"ä½¿ç”¨æ›¿ä»£è·¯å¾„: {alt_path}")
                break
        else:
            raise FileNotFoundError(f"CosyVoice model not found at {model_path} or alternative paths: {alt_paths}")

    # Check which config file exists and use appropriate class
    cosyvoice2_yaml = full_path / "cosyvoice2.yaml"
    cosyvoice_yaml = full_path / "cosyvoice.yaml"

    try:
        if cosyvoice2_yaml.exists():
            cosyvoice_model = CosyVoice2(str(full_path), load_jit=False, load_trt=False, fp16=False)
            print(f"Loaded CosyVoice2 from {full_path}")
        elif cosyvoice_yaml.exists():
            cosyvoice_model = CosyVoice(str(full_path), load_jit=False, load_trt=False, fp16=False)
            print(f"Loaded CosyVoice from {full_path}")
        else:
            raise FileNotFoundError(f"Neither cosyvoice2.yaml nor cosyvoice.yaml found in {full_path}")
    except Exception as e:
        raise RuntimeError(f"Failed to load CosyVoice model: {e}")

def initialize_dolphin(model_name: str = "paraformer-zh"):
    """Initialize Dolphin/FunASR model"""
    global dolphin_model

    try:
        from funasr import AutoModel

        model_dir = Path(__file__).parent / "models" / "dolphin"
        model_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®ç¼“å­˜ç›®å½•
        os.environ['FUNASR_CACHE_HOME'] = str(model_dir)

        dolphin_model = AutoModel(model=model_name, cache_dir=str(model_dir))
        print(f"Loaded FunASR {model_name} model")

    except ImportError:
        raise RuntimeError("FunASR not available, please install: pip install funasr")
    except Exception as e:
        raise RuntimeError(f"Failed to load FunASR model: {e}")

@app.on_event("startup")
async def startup_event():
    """Initialize models on startup"""
    # èŽ·å–é…ç½®çš„æ¨¡åž‹è·¯å¾„
    cosyvoice_model_path = globals().get('COSYVOICE_MODEL_PATH', 'CosyVoice/pretrained_models/CosyVoice2-0.5B')
    dolphin_model_name = globals().get('DOLPHIN_MODEL_NAME', 'paraformer-zh')

    print("=" * 50)
    print("OpenAI Compatible Audio API å¯åŠ¨ä¸­...")
    print("=" * 50)

    print("ðŸ” æ£€æŸ¥æ¨¡åž‹çŠ¶æ€...")

    # æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡åž‹
    try:
        cosyvoice_ready, dolphin_ready = check_and_download_models(cosyvoice_model_path)
    except Exception as e:
        print(f"âŒ æ¨¡åž‹æ£€æŸ¥/ä¸‹è½½å¤±è´¥: {e}")
        print("âš ï¸ å°†å°è¯•ç»§ç»­å¯åŠ¨ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

    print("\nðŸš€ åˆå§‹åŒ–æ¨¡åž‹...")

    # åˆå§‹åŒ–CosyVoice
    try:
        initialize_cosyvoice(cosyvoice_model_path)
        print("âœ… CosyVoice TTSæœåŠ¡å·²å¯åŠ¨")
    except Exception as e:
        print(f"âŒ CosyVoiceåˆå§‹åŒ–å¤±è´¥: {e}")
        print("âš ï¸ TTSåŠŸèƒ½å°†ä¸å¯ç”¨")

    # åˆå§‹åŒ–Dolphin/FunASR
    try:
        initialize_dolphin(dolphin_model_name)
        print("âœ… FunASRè½¬å½•æœåŠ¡å·²å¯åŠ¨")
    except Exception as e:
        print(f"âŒ FunASRåˆå§‹åŒ–å¤±è´¥: {e}")
        print("âš ï¸ ASRåŠŸèƒ½å°†ä¸å¯ç”¨")

    print("\n" + "=" * 50)
    print("ðŸŽ‰ APIæœåŠ¡å™¨å¯åŠ¨å®Œæˆï¼")
    print(f"ðŸŽ™ï¸  CosyVoice TTS: {'âœ… å¯ç”¨' if cosyvoice_model else 'âŒ ä¸å¯ç”¨'}")
    print(f"ðŸŽ§ FunASR è½¬å½•: {'âœ… å¯ç”¨' if dolphin_model else 'âŒ ä¸å¯ç”¨'}")
    print("ðŸŒ æœåŠ¡åœ°å€: http://127.0.0.1:8000")
    print("ðŸ“– APIæ–‡æ¡£: http://127.0.0.1:8000/docs")
    print("=" * 50)

@app.post("/v1/audio/speech")
async def create_speech(request: TTSRequest):
    """
    Create speech from text using CosyVoice
    Compatible with OpenAI's /v1/audio/speech endpoint
    """
    if cosyvoice_model is None:
        raise HTTPException(status_code=503, detail="CosyVoice model not available")
    
    try:
        # Map OpenAI voices to CosyVoice speakers
        voice_mapping = {
            "alloy": "ä¸­æ–‡å¥³",
            "echo": "ä¸­æ–‡ç”·", 
            "fable": "è‹±æ–‡å¥³",
            "onyx": "è‹±æ–‡ç”·",
            "nova": "ä¸­æ–‡å¥³",
            "shimmer": "ä¸­æ–‡å¥³"
        }
        
        speaker = voice_mapping.get(request.voice, "ä¸­æ–‡å¥³")
        
        # Check available speakers
        available_spks = cosyvoice_model.list_available_spks()
        if available_spks and speaker not in available_spks:
            speaker = available_spks[0] if available_spks else "ä¸­æ–‡å¥³"
        
        # Generate speech
        speech_data = None
        if hasattr(cosyvoice_model, 'inference_sft') and available_spks:
            # Use SFT mode if available
            for i, output in enumerate(cosyvoice_model.inference_sft(
                request.input, speaker, stream=False, speed=request.speed
            )):
                speech_data = output['tts_speech']
                break
        elif hasattr(cosyvoice_model, 'inference_zero_shot'):
            # Use zero-shot mode with default prompt
            prompt_path = Path(__file__).parent / "CosyVoice" / "asset" / "zero_shot_prompt.wav"
            if prompt_path.exists():
                prompt_speech = load_wav(str(prompt_path), 16000)
                for i, output in enumerate(cosyvoice_model.inference_zero_shot(
                    request.input, "å¸Œæœ›ä½ ä»¥åŽèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚", prompt_speech, 
                    stream=False, speed=request.speed
                )):
                    speech_data = output['tts_speech']
                    break
            else:
                raise HTTPException(status_code=500, detail="No prompt audio found for zero-shot")
        
        if speech_data is None:
            raise HTTPException(status_code=500, detail="Failed to generate speech")
        
        # Convert to numpy and save as wav
        audio_numpy = speech_data.cpu().numpy().flatten()
        
        # Create temporary file for audio conversion
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            torchaudio.save(tmp_file.name, speech_data, cosyvoice_model.sample_rate)
            
            # Read the audio file
            with open(tmp_file.name, "rb") as f:
                audio_bytes = f.read()
            
            # Clean up temp file
            os.unlink(tmp_file.name)
        
        # Return appropriate format
        if request.response_format == "mp3":
            # For simplicity, return WAV with MP3 content-type
            # In production, you'd want to convert to actual MP3
            return Response(content=audio_bytes, media_type="audio/mpeg")
        elif request.response_format == "wav":
            return Response(content=audio_bytes, media_type="audio/wav")
        else:
            return Response(content=audio_bytes, media_type="audio/wav")
            
    except Exception as e:
        print(f"TTS Error: {e}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Speech generation failed: {str(e)}")

@app.post("/v1/audio/transcriptions", response_model=TranscriptionResponse)
async def create_transcription(
    file: UploadFile = File(...),
    model: str = Form("whisper-1"),
    language: Optional[str] = Form(None),
    prompt: Optional[str] = Form(None),
    response_format: str = Form("json"),
    temperature: float = Form(0.0)
):
    """
    Transcribe audio to text using FunASR
    Compatible with OpenAI's /v1/audio/transcriptions endpoint
    """
    if dolphin_model is None:
        raise HTTPException(status_code=503, detail="FunASR model not available")

    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # Use FunASR for transcription
            result = dolphin_model(tmp_file_path)

            # Clean up temp file
            os.unlink(tmp_file_path)

            # Extract text from result
            if hasattr(result, 'text'):
                text = result.text
            elif isinstance(result, list) and len(result) > 0:
                # Handle list output
                text = ""
                for item in result:
                    if hasattr(item, 'text'):
                        text += item.text
                    elif isinstance(item, dict) and 'text' in item:
                        text += item['text']
                    elif isinstance(item, str):
                        text += item
            elif isinstance(result, dict) and 'text' in result:
                text = result['text']
            else:
                text = str(result)

            return TranscriptionResponse(text=text.strip())

        except Exception as e:
            # Clean up temp file on error
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)
            raise e

    except Exception as e:
        print(f"Transcription Error: {e}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Transcription failed: {str(e)}")

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "cosyvoice_available": cosyvoice_model is not None,
        "dolphin_available": dolphin_model is not None
    }

@app.get("/v1/models")
async def list_models():
    """List available models (OpenAI compatible)"""
    models = []
    
    if cosyvoice_model is not None:
        models.extend([
            {"id": "tts-1", "object": "model", "created": 1677610602, "owned_by": "cosyvoice"},
            {"id": "tts-1-hd", "object": "model", "created": 1677610602, "owned_by": "cosyvoice"}
        ])
    
    if dolphin_model is not None:
        models.extend([
            {"id": "whisper-1", "object": "model", "created": 1677610602, "owned_by": "dolphin"}
        ])
    
    return {"object": "list", "data": models}

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind to") 
    parser.add_argument("--cosyvoice-model", type=str, 
                       default="CosyVoice/pretrained_models/CosyVoice2-0.5B",
                       help="CosyVoice model path")
    parser.add_argument("--dolphin-model", type=str, default="paraformer-zh",
                       help="FunASR model name (paraformer-zh, paraformer-en, etc.)")
    
    args = parser.parse_args()
    
    # Override defaults
    globals()['COSYVOICE_MODEL_PATH'] = args.cosyvoice_model
    globals()['DOLPHIN_MODEL_NAME'] = args.dolphin_model
    
    print(f"Starting OpenAI-compatible API server on {args.host}:{args.port}")
    print(f"CosyVoice model: {args.cosyvoice_model}")
    print(f"Dolphin model: {args.dolphin_model}")
    
    uvicorn.run(app, host=args.host, port=args.port)