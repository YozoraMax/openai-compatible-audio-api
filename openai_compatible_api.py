#!/usr/bin/env python3
"""
OpenAI-compatible API server for CosyVoice (TTS) and FunASR (ASR)
Provides /v1/audio/speech and /v1/audio/transcriptions endpoints
"""

import sys
import os
import io
import base64
import tempfile
import traceback
from pathlib import Path
from typing import Optional, List

import torch
import torchaudio
import numpy as np
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import Response
from pydantic import BaseModel
import uvicorn

# Add CosyVoice to path
sys.path.append(str(Path(__file__).parent / "CosyVoice" / "third_party" / "Matcha-TTS"))
sys.path.append(str(Path(__file__).parent / "CosyVoice"))

# Note: Dolphin directory is kept for historical reference but not used

# Import CosyVoice
CosyVoice = None
CosyVoice2 = None
load_wav = None

try:
    # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÁ¶ÅÁî®‰∏Ä‰∫õÂèØÈÄâÂäüËÉΩ
    os.environ['MATCHA_DISABLE_COMPILE'] = '1'

    # Â∞ùËØïÂàõÂª∫matchaÊ®°ÂùóÂ≠òÊ†πÔºàÂ¶ÇÊûú‰∏çÂ≠òÂú®Ôºâ
    matcha_dir = Path(__file__).parent / "CosyVoice" / "third_party" / "Matcha-TTS"
    if not matcha_dir.exists():
        matcha_dir.mkdir(parents=True, exist_ok=True)
        (matcha_dir / "__init__.py").write_text("")

    # Ê∑ªÂä†Âà∞PythonË∑ØÂæÑ
    if str(matcha_dir) not in sys.path:
        sys.path.insert(0, str(matcha_dir))

    from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
    from cosyvoice.utils.file_utils import load_wav
    print("‚úì CosyVoiceÂØºÂÖ•ÊàêÂäü")
except ImportError as e:
    print(f"‚ö†Ô∏è CosyVoiceÂØºÂÖ•Â§±Ë¥•: {e}")
    print("üí° Ëß£ÂÜ≥ÊñπÊ°àÔºö")
    print("   1. ËøêË°å: python3 install_dependencies.py")
    print("   2. ÊàñÊâãÂä®ÂÆâË£Ö: pip install matcha-tts einops phonemizer")
except Exception as e:
    print(f"‚ùå CosyVoiceÂàùÂßãÂåñÈîôËØØ: {e}")
    print("üí° ËøôÂèØËÉΩÊòØÊ®°ÂûãÂä†ËΩΩÈóÆÈ¢òÔºåÊúçÂä°Âô®Â∞ÜÁªßÁª≠ÂêØÂä®‰ΩÜTTSÂäüËÉΩ‰∏çÂèØÁî®")

# FunASR for speech recognition
print("‚ÑπÔ∏è ‰ΩøÁî®FunASRËøõË°åËØ≠Èü≥ËØÜÂà´")

app = FastAPI(title="OpenAI Compatible Audio API", version="1.0.0")

# Global models
cosyvoice_model = None
funasr_model = None

def fix_cosyvoice_model_path(expected_model_path: str = "models/cosyvoice/CosyVoice2-0.5B"):
    """‰øÆÂ§çCosyVoiceÊ®°ÂûãË∑ØÂæÑÈóÆÈ¢ò - Áªü‰∏Ä‰ΩøÁî®modelsÁõÆÂΩï"""
    base_dir = Path(__file__).parent

    # Á°Æ‰øùmodelsÁõÆÂΩïÁªìÊûÑÂ≠òÂú®
    models_dir = base_dir / "models"
    cosyvoice_dir = models_dir / "cosyvoice"
    cosyvoice_dir.mkdir(parents=True, exist_ok=True)

    # APIÊúüÊúõÁöÑË∑ØÂæÑ
    expected_path = base_dir / expected_model_path

    # Â¶ÇÊûúÊúüÊúõË∑ØÂæÑÂ∑≤Â≠òÂú®‰∏îÊúâÊïàÔºåÁõ¥Êé•ËøîÂõû
    if expected_path.exists():
        config_files = list(expected_path.glob("*.yaml"))
        if config_files:
            print(f"‚úì CosyVoiceÊ®°ÂûãË∑ØÂæÑÊ≠£Á°Æ: {expected_model_path}")
            return True

    # Ê£ÄÊü•ÂèØËÉΩÁöÑÊóßË∑ØÂæÑÔºàÁî®‰∫éËøÅÁßªÔºâ
    potential_old_paths = [
        base_dir / "CosyVoice" / "pretrained_models" / "iic" / "CosyVoice2-0.5B",
        base_dir / "CosyVoice" / "pretrained_models" / "CosyVoice2-0.5B", 
        base_dir / "CosyVoice" / "pretrained_models" / "CosyVoice-300M-SFT",
        base_dir / "CosyVoice" / "pretrained_models" / "CosyVoice-300M",
    ]

    # Ê£ÄÊü•modelsÁõÆÂΩï‰∏ãÂèØËÉΩÁöÑË∑ØÂæÑ
    potential_paths = [
        base_dir / "models" / "cosyvoice" / "iic" / "CosyVoice2-0.5B",
        base_dir / "models" / "cosyvoice" / "CosyVoice2-0.5B",
        base_dir / "models" / "cosyvoice" / "CosyVoice-300M-SFT", 
        base_dir / "models" / "cosyvoice" / "CosyVoice-300M",
    ] + potential_old_paths

    for actual_path in potential_paths:
        if actual_path.exists() and actual_path.is_dir():
            # Ê£ÄÊü•ÊòØÂê¶ÊúâÈÖçÁΩÆÊñá‰ª∂
            config_files = list(actual_path.glob("*.yaml"))
            if config_files:
                print(f"ÊâæÂà∞CosyVoiceÊ®°Âûã: {actual_path}")
                print(f"ÈÖçÁΩÆÊñá‰ª∂: {[f.name for f in config_files]}")

                # Â¶ÇÊûúÊ®°ÂûãÂú®ÊóßË∑ØÂæÑÔºåËøÅÁßªÂà∞Êñ∞ÁöÑmodelsÁõÆÂΩï
                if not str(actual_path).startswith(str(models_dir)):
                    new_path = cosyvoice_dir / actual_path.name
                    print(f"üîÑ ËøÅÁßªÊ®°ÂûãÂà∞Áªü‰∏ÄÁõÆÂΩï: {actual_path} -> {new_path}")
                    try:
                        import shutil
                        if new_path.exists():
                            shutil.rmtree(new_path)
                        shutil.move(str(actual_path), str(new_path))
                        actual_path = new_path
                        print(f"‚úÖ Ê®°ÂûãËøÅÁßªÂÆåÊàê: {new_path}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Ê®°ÂûãËøÅÁßªÂ§±Ë¥•Ôºå‰ΩøÁî®ÂéüË∑ØÂæÑ: {e}")

                # Á°Æ‰øùÊúüÊúõË∑ØÂæÑÊåáÂêëÊ≠£Á°ÆÁöÑÊ®°Âûã
                if actual_path != expected_path:
                    expected_path.parent.mkdir(parents=True, exist_ok=True)
                    if not expected_path.exists():
                        try:
                            expected_path.symlink_to(actual_path, target_is_directory=True)
                            print(f"‚úì ÂàõÂª∫Á¨¶Âè∑ÈìæÊé•: {expected_path} -> {actual_path}")
                        except OSError:
                            print(f"‚ö†Ô∏è Á¨¶Âè∑ÈìæÊé•ÂàõÂª∫Â§±Ë¥•ÔºåÁõ¥Êé•‰ΩøÁî®Ë∑ØÂæÑ: {actual_path}")
                
                return True

    return False

def check_and_download_models(cosyvoice_model_path: str = "models/cosyvoice/CosyVoice2-0.5B"):
    """Ê£ÄÊü•Âπ∂‰∏ãËΩΩÂøÖË¶ÅÁöÑÊ®°ÂûãÂà∞Áªü‰∏ÄÁöÑmodelsÁõÆÂΩï"""
    print("üìÅ Ê£ÄÊü•Âπ∂ÂàõÂª∫modelsÁõÆÂΩïÁªìÊûÑ...")
    
    base_dir = Path(__file__).parent
    models_dir = base_dir / "models"
    models_dir.mkdir(exist_ok=True)
    
    print("‚úÖ modelsÁõÆÂΩïÂ∑≤ÂàõÂª∫")
    print("üîç Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂...")

    # Ê£ÄÊü•Âπ∂‰øÆÂ§çCosyVoiceÊ®°ÂûãË∑ØÂæÑ
    cosyvoice_ready = fix_cosyvoice_model_path(cosyvoice_model_path)

    if not cosyvoice_ready:
        print(f"‚úó CosyVoiceÊ®°Âûã‰∏çÂ≠òÂú®ÔºåÂºÄÂßã‰∏ãËΩΩÂà∞: {cosyvoice_model_path}")
        try:
            download_cosyvoice_model(cosyvoice_model_path)
            # ‰∏ãËΩΩÂêéÂÜçÊ¨°Â∞ùËØï‰øÆÂ§çË∑ØÂæÑ
            cosyvoice_ready = fix_cosyvoice_model_path(cosyvoice_model_path)
        except Exception as e:
            print(f"CosyVoiceÊ®°Âûã‰∏ãËΩΩÂ§±Ë¥•: {e}")
            cosyvoice_ready = False

    # Ê£ÄÊü•FunASRÊ®°Âûã
    funasr_ready = False
    try:
        from funasr import AutoModel
        # ÁÆÄÂçïÊ£ÄÊü•ÊòØÂê¶ÂèØ‰ª•ÂàùÂßãÂåñÊ®°ÂûãÔºà‰ºöËá™Âä®‰∏ãËΩΩÔºâ
        print("üîç Ê£ÄÊü•FunASRÊ®°Âûã...")
        model_dir = models_dir / "funasr"
        model_dir.mkdir(parents=True, exist_ok=True)

        # ËÆæÁΩÆÁºìÂ≠òÁõÆÂΩï
        os.environ['FUNASR_CACHE_HOME'] = str(model_dir)

        # Â∞ùËØïÂä†ËΩΩÊ®°ÂûãÔºàÂ¶ÇÊûú‰∏çÂ≠òÂú®‰ºöËá™Âä®‰∏ãËΩΩÔºâ
        print("‚¨áÔ∏è ÂàùÂßãÂåñFunASRÊ®°ÂûãÔºàÂ¶ÇÈúÄË¶Å‰ºöËá™Âä®‰∏ãËΩΩÂà∞models/funasrÔºâ...")
        test_model = AutoModel(model="paraformer-zh", cache_dir=str(model_dir))
        print("‚úÖ FunASRÊ®°ÂûãÂáÜÂ§áÂ∞±Áª™")
        funasr_ready = True

    except ImportError:
        print("‚úó FunASRÊú™ÂÆâË£ÖÔºåËØ∑ËøêË°å: pip install funasr")
    except Exception as e:
        print(f"‚úó FunASRÊ®°ÂûãÂàùÂßãÂåñÂ§±Ë¥•: {e}")

    return cosyvoice_ready, funasr_ready

def download_cosyvoice_model(model_path: str):
    """‰∏ãËΩΩCosyVoiceÊ®°ÂûãÂà∞modelsÁõÆÂΩï"""
    try:
        from modelscope import snapshot_download

        base_dir = Path(__file__).parent
        models_dir = base_dir / "models" / "cosyvoice"
        models_dir.mkdir(parents=True, exist_ok=True)

        print("‚¨áÔ∏è ‰ªéModelScope‰∏ãËΩΩCosyVoiceÊ®°ÂûãÂà∞models/cosyvoiceÁõÆÂΩï...")
        print("üìä Ê®°ÂûãÂ§ßÂ∞èÁ∫¶2GBÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖ...")
        
        # ‰∏ãËΩΩÂà∞models/cosyvoiceÁõÆÂΩï
        downloaded_path = snapshot_download(
            'iic/CosyVoice2-0.5B',
            cache_dir=str(models_dir)
        )
        print(f"‚úÖ CosyVoiceÊ®°Âûã‰∏ãËΩΩÂÆåÊàê: {downloaded_path}")
        
        # Ê£ÄÊü•‰∏ãËΩΩÁöÑÊ®°ÂûãÊòØÂê¶Âú®È¢ÑÊúü‰ΩçÁΩÆ
        expected_model_path = models_dir / "iic" / "CosyVoice2-0.5B"
        if expected_model_path.exists():
            print(f"‚úÖ Ê®°ÂûãÂ∑≤‰øùÂ≠òÂà∞: {expected_model_path}")
        else:
            print(f"‚ö†Ô∏è Ê®°ÂûãÂèØËÉΩÂú®ÂÖ∂‰ªñ‰ΩçÁΩÆ: {downloaded_path}")

        # ‰∏ãËΩΩÂÆåÊàêÂêéÔºåË∞ÉÁî®Ë∑ØÂæÑ‰øÆÂ§çÂáΩÊï∞
        fix_cosyvoice_model_path(model_path)

        return downloaded_path

    except ImportError:
        print("‚úó ModelScopeÊú™ÂÆâË£ÖÔºåËØ∑ËøêË°å: pip install modelscope")
        raise RuntimeError("Êó†Ê≥ï‰∏ãËΩΩCosyVoiceÊ®°ÂûãÔºåModelScopeÊú™ÂÆâË£Ö")
    except Exception as e:
        print(f"‚úó CosyVoiceÊ®°Âûã‰∏ãËΩΩÂ§±Ë¥•: {e}")
        raise RuntimeError(f"CosyVoiceÊ®°Âûã‰∏ãËΩΩÂ§±Ë¥•: {e}")

class TTSRequest(BaseModel):
    model: str = "tts-1"
    input: str
    voice: str = "alloy"
    response_format: str = "mp3"
    speed: float = 1.0

class TranscriptionResponse(BaseModel):
    text: str

def create_default_prompt_audio():
    """ÂàõÂª∫ÈªòËÆ§ÁöÑÈõ∂Ê†∑Êú¨ÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂Âà∞modelsÁõÆÂΩï"""
    try:
        import numpy as np

        # ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊ≠£Âº¶Ê≥¢‰Ωú‰∏∫ÈªòËÆ§ÊèêÁ§∫Èü≥È¢ëÔºà1ÁßíÔºå16kHzÔºâ
        sample_rate = 16000
        duration = 1.0  # 1Áßí
        frequency = 220  # ‰ΩéÈü≥AÔºåÊõ¥Êé•Ëøë‰∫∫Â£∞

        t = np.linspace(0, duration, int(sample_rate * duration), False)
        # ÂàõÂª∫‰∏Ä‰∏™Â§çÂêàÊ≥¢ÂΩ¢ÔºåÊ®°ÊãüÁÆÄÂçïËØ≠Èü≥
        audio = (np.sin(2 * np.pi * frequency * t) * 0.5 +
                np.sin(2 * np.pi * frequency * 2 * t) * 0.3 +
                np.sin(2 * np.pi * frequency * 3 * t) * 0.2)

        # Ê∑ªÂä†ÂåÖÁªúÔºå‰ΩøÂÖ∂Êõ¥ÂÉèËØ≠Èü≥
        envelope = np.exp(-t * 1.5) * (1 - np.exp(-t * 10))
        audio = audio * envelope * 0.3

        # ËΩ¨Êç¢‰∏∫torch tensor
        audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)

        # ‰øùÂ≠òÈü≥È¢ëÊñá‰ª∂Âà∞modelsÁõÆÂΩï
        asset_dir = Path(__file__).parent / "models" / "cosyvoice" / "asset"
        asset_dir.mkdir(parents=True, exist_ok=True)

        output_path = asset_dir / "zero_shot_prompt.wav"
        torchaudio.save(str(output_path), audio_tensor, sample_rate)

        print(f"‚úÖ ÈªòËÆ§ÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂Â∑≤ÂàõÂª∫: {output_path}")
        return output_path

    except Exception as e:
        print(f"‚ö†Ô∏è ÂàõÂª∫ÈªòËÆ§ÊèêÁ§∫Èü≥È¢ëÂ§±Ë¥•: {e}")
        return None

def initialize_cosyvoice(model_path: str = "models/cosyvoice/CosyVoice2-0.5B"):
    """Initialize CosyVoice model"""
    global cosyvoice_model
    import time

    if not CosyVoice or not CosyVoice2:
        raise RuntimeError("CosyVoice not available")

    print(f"üîÑ ÂºÄÂßãÂä†ËΩΩ CosyVoice Ê®°Âûã...")
    start_time = time.time()

    full_path = Path(__file__).parent / model_path
    print(f"üìÇ Ê®°ÂûãË∑ØÂæÑ: {model_path}")

    if not full_path.exists():
        # Try alternative paths including models directory and legacy paths
        alt_paths = [
            "models/cosyvoice/iic/CosyVoice2-0.5B",  # ModelScope‰∏ãËΩΩÂà∞modelsÁõÆÂΩïÁöÑË∑ØÂæÑ
            "models/cosyvoice/CosyVoice-300M-SFT",
            "models/cosyvoice/CosyVoice-300M", 
            "CosyVoice/pretrained_models/iic/CosyVoice2-0.5B",  # ÊóßË∑ØÂæÑÂÖºÂÆπ
            "CosyVoice/pretrained_models/CosyVoice2-0.5B",
            "CosyVoice/pretrained_models/CosyVoice-300M-SFT",
            "CosyVoice/pretrained_models/CosyVoice-300M",
        ]
        for alt_path in alt_paths:
            alt_full_path = Path(__file__).parent / alt_path
            if alt_full_path.exists():
                full_path = alt_full_path
                print(f"‚úÖ ‰ΩøÁî®ÂèëÁé∞ÁöÑÊ®°ÂûãË∑ØÂæÑ: {alt_path}")
                break
        else:
            raise FileNotFoundError(f"CosyVoice model not found at {model_path} or alternative paths: {alt_paths}")

    # Check which config file exists and use appropriate class
    cosyvoice2_yaml = full_path / "cosyvoice2.yaml"
    cosyvoice_yaml = full_path / "cosyvoice.yaml"

    try:
        print("‚è≥ Ê≠£Âú®ÂàùÂßãÂåñÊ®°ÂûãÂèÇÊï∞...")
        if cosyvoice2_yaml.exists():
            print("üìÑ ‰ΩøÁî® CosyVoice2 ÈÖçÁΩÆ")
            cosyvoice_model = CosyVoice2(str(full_path), load_jit=False, load_trt=False, fp16=False)
            model_type = "CosyVoice2"
        elif cosyvoice_yaml.exists():
            print("üìÑ ‰ΩøÁî® CosyVoice ÈÖçÁΩÆ")
            cosyvoice_model = CosyVoice(str(full_path), load_jit=False, load_trt=False, fp16=False)
            model_type = "CosyVoice"
        else:
            raise FileNotFoundError(f"Neither cosyvoice2.yaml nor cosyvoice.yaml found in {full_path}")

        elapsed = time.time() - start_time
        print(f"‚úÖ {model_type} Ê®°ÂûãÂä†ËΩΩÂÆåÊàê (ËÄóÊó∂: {elapsed:.1f}Áßí)")

        # Ê£ÄÊü•Èõ∂Ê†∑Êú¨Êé®ÁêÜÈü≥È¢ëÊñá‰ª∂
        # ‰ºòÂÖàÊü•ÊâæCosyVoiceÂéüÁîüassetÊñá‰ª∂
        cosyvoice_asset_paths = [
            Path(__file__).parent / "CosyVoice" / "asset" / "zero_shot_prompt.wav",
            Path(__file__).parent / "CosyVoice" / "asset" / "samples" / "zero_shot_prompt.wav",
            Path(__file__).parent / "CosyVoice" / "asset" / "samples" / "cross_lingual_prompt.wav",
            Path(__file__).parent / "CosyVoice" / "asset" / "instruct_prompt.wav",
        ]
        
        original_asset_found = False
        for asset_path in cosyvoice_asset_paths:
            if asset_path.exists():
                print(f"‚úÖ ÂèëÁé∞CosyVoiceÂéüÁîüÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂: {asset_path}")
                original_asset_found = True
                break
        
        if not original_asset_found:
            # Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞ÂéüÁîüÊñá‰ª∂ÔºåÂàõÂª∫Â§áÁî®Êñá‰ª∂Âà∞modelsÁõÆÂΩï
            asset_dir = Path(__file__).parent / "models" / "cosyvoice" / "asset"
            asset_dir.mkdir(parents=True, exist_ok=True)
            prompt_path = asset_dir / "zero_shot_prompt.wav"
            
            if not prompt_path.exists():
                print("üéµ Êú™ÊâæÂà∞CosyVoiceÂéüÁîüÈü≥È¢ëÊñá‰ª∂ÔºåÊ≠£Âú®ÂàõÂª∫Â§áÁî®Êñá‰ª∂...")
                create_default_prompt_audio()
            else:
                print(f"‚úÖ Â§áÁî®ÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂Â∑≤Â≠òÂú®: {prompt_path}")
        else:
            print("‚úÖ Â∞Ü‰ºòÂÖà‰ΩøÁî®CosyVoiceÂéüÁîüÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂ËøõË°åÈõ∂Ê†∑Êú¨Êé®ÁêÜ")

    except Exception as e:
        raise RuntimeError(f"Failed to load CosyVoice model: {e}")

def initialize_funasr(model_name: str = "paraformer-zh"):
    """Initialize FunASR model"""
    global funasr_model

    try:
        from funasr import AutoModel
        import time

        model_dir = Path(__file__).parent / "models" / "funasr"
        model_dir.mkdir(parents=True, exist_ok=True)

        # ËÆæÁΩÆÁºìÂ≠òÁõÆÂΩï
        os.environ['FUNASR_CACHE_HOME'] = str(model_dir)

        print(f"üîÑ ÂºÄÂßãÂä†ËΩΩ FunASR Ê®°Âûã: {model_name}")
        start_time = time.time()

        # Â∞èÊ®°ÂûãÊò†Â∞Ñ - ‰ΩøÁî®FunASRÂÆûÈôÖÊîØÊåÅÁöÑÊ®°ÂûãÂêçÁß∞
        model_sizes = {
            "paraformer-zh": "Ê†áÂáÜ‰∏≠ÊñáÊ®°Âûã (~1GB)",
            "iic/speech_paraformer-zh-small_asr_nat-zh-cn-16k-common-vocab8404-pytorch": "Â∞èÊ®°Âûã (~300MB)",
            "paraformer-zh-streaming": "ÊµÅÂºèÊ®°Âûã (~840MB)",
            "paraformer-en": "Ëã±ÊñáÊ®°Âûã (~800MB)"
        }

        size_info = model_sizes.get(model_name, "Êú™Áü•Â§ßÂ∞è")
        print(f"üìä Ê®°Âûã‰ø°ÊÅØ: {size_info}")
        print("‚è≥ Ê≠£Âú®‰∏ãËΩΩ/Âä†ËΩΩÊ®°ÂûãÔºåËØ∑Á®çÂÄô...")
        print("üí° ÊèêÁ§∫: Ê®°ÂûãÂä†ËΩΩÂèØËÉΩÈúÄË¶ÅÂá†ÂàÜÈíüÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖ...")

        # Ê∑ªÂä†Âä†ËΩΩËøõÂ∫¶ÊèêÁ§∫
        import threading
        import time

        def progress_indicator():
            dots = 0
            while not hasattr(progress_indicator, 'stop'):
                dots = (dots + 1) % 4
                print(f"\r‚è≥ Ê®°ÂûãÂä†ËΩΩ‰∏≠{'.' * dots}{' ' * (3 - dots)}", end='', flush=True)
                time.sleep(1)

        progress_thread = threading.Thread(target=progress_indicator, daemon=True)
        progress_thread.start()

        try:
            funasr_model = AutoModel(model=model_name, cache_dir=str(model_dir))
        finally:
            progress_indicator.stop = True
            print("\r", end='')  # Ê∏ÖÈô§ËøõÂ∫¶ÊåáÁ§∫Âô®

        elapsed = time.time() - start_time
        print(f"‚úÖ FunASR {model_name} Ê®°ÂûãÂä†ËΩΩÂÆåÊàê (ËÄóÊó∂: {elapsed:.1f}Áßí)")

    except ImportError:
        raise RuntimeError("FunASR not available, please install: pip install funasr")
    except Exception as e:
        raise RuntimeError(f"Failed to load FunASR model: {e}")

@app.on_event("startup")
async def startup_event():
    """Initialize models on startup"""
    # Ëé∑ÂèñÈÖçÁΩÆÁöÑÊ®°ÂûãË∑ØÂæÑ - ÈªòËÆ§‰ΩøÁî®modelsÁõÆÂΩï
    cosyvoice_model_path = globals().get('COSYVOICE_MODEL_PATH', 'models/cosyvoice/CosyVoice2-0.5B')
    asr_model_name = globals().get('ASR_MODEL_NAME', 'paraformer-zh')
    tts_only_mode = globals().get('TTS_ONLY_MODE', False)

    print("=" * 50)
    print("OpenAI Compatible Audio API ÂêØÂä®‰∏≠...")
    if tts_only_mode:
        print("üöÄ TTS‰∏ìÁî®Ê®°Âºè - ‰ªÖÂêØÁî®ÊñáÊú¨ËΩ¨ËØ≠Èü≥ÂäüËÉΩ")
    print("=" * 50)

    print("üîç Ê£ÄÊü•Ê®°ÂûãÁä∂ÊÄÅ...")

    # Ê£ÄÊü•Âπ∂‰∏ãËΩΩÊ®°Âûã
    try:
        cosyvoice_ready, funasr_ready = check_and_download_models(cosyvoice_model_path)
    except Exception as e:
        print(f"‚ùå Ê®°ÂûãÊ£ÄÊü•/‰∏ãËΩΩÂ§±Ë¥•: {e}")
        print("‚ö†Ô∏è Â∞ÜÂ∞ùËØïÁªßÁª≠ÂêØÂä®ÔºåÊüê‰∫õÂäüËÉΩÂèØËÉΩ‰∏çÂèØÁî®")

    print("\nüöÄ ÂàùÂßãÂåñÊ®°Âûã...")

    # ÂàùÂßãÂåñCosyVoice
    try:
        initialize_cosyvoice(cosyvoice_model_path)
        print("‚úÖ CosyVoice TTSÊúçÂä°Â∑≤ÂêØÂä®")
    except Exception as e:
        print(f"‚ùå CosyVoiceÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        print("‚ö†Ô∏è TTSÂäüËÉΩÂ∞Ü‰∏çÂèØÁî®")

    # ÂàùÂßãÂåñFunASR (Èô§ÈùûÊòØTTS‰∏ìÁî®Ê®°Âºè)
    if not tts_only_mode:
        try:
            initialize_funasr(asr_model_name)
            print("‚úÖ FunASRËΩ¨ÂΩïÊúçÂä°Â∑≤ÂêØÂä®")
        except Exception as e:
            print(f"‚ùå FunASRÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            print("‚ö†Ô∏è ASRÂäüËÉΩÂ∞Ü‰∏çÂèØÁî®")
    else:
        print("‚è≠Ô∏è TTS‰∏ìÁî®Ê®°ÂºèÔºåË∑≥ËøáASRÊ®°ÂûãÂä†ËΩΩ")

    print("\n" + "=" * 50)
    print("üéâ APIÊúçÂä°Âô®ÂêØÂä®ÂÆåÊàêÔºÅ")
    print(f"üéôÔ∏è  CosyVoice TTS: {'‚úÖ ÂèØÁî®' if cosyvoice_model else '‚ùå ‰∏çÂèØÁî®'}")
    if tts_only_mode:
        print("üéß FunASR ËΩ¨ÂΩï: ‚è≠Ô∏è TTS‰∏ìÁî®Ê®°ÂºèÂ∑≤Á¶ÅÁî®")
    else:
        print(f"üéß FunASR ËΩ¨ÂΩï: {'‚úÖ ÂèØÁî®' if funasr_model else '‚ùå ‰∏çÂèØÁî®'}")
    print("üåê ÊúçÂä°Âú∞ÂùÄ: http://127.0.0.1:8000")
    print("üìñ APIÊñáÊ°£: http://127.0.0.1:8000/docs")
    print("=" * 50)

@app.post("/v1/audio/speech")
async def create_speech(request: TTSRequest):
    """
    Create speech from text using CosyVoice
    Compatible with OpenAI's /v1/audio/speech endpoint
    """
    if cosyvoice_model is None:
        raise HTTPException(status_code=503, detail="CosyVoice model not available")
    
    try:
        # Map OpenAI voices to CosyVoice speakers
        voice_mapping = {
            "alloy": "‰∏≠ÊñáÂ•≥",
            "echo": "‰∏≠ÊñáÁî∑", 
            "fable": "Ëã±ÊñáÂ•≥",
            "onyx": "Ëã±ÊñáÁî∑",
            "nova": "‰∏≠ÊñáÂ•≥",
            "shimmer": "‰∏≠ÊñáÂ•≥"
        }
        
        speaker = voice_mapping.get(request.voice, "‰∏≠ÊñáÂ•≥")
        
        # Check available speakers and methods
        print(f"üîç Ê£ÄÊü•CosyVoiceÊ®°ÂûãÂèØÁî®ÊñπÊ≥ï...")
        available_methods = [method for method in dir(cosyvoice_model) if not method.startswith('_')]
        print(f"üìã ÂèØÁî®ÊñπÊ≥ï: {available_methods}")

        available_spks = None
        try:
            available_spks = cosyvoice_model.list_available_spks()
            print(f"üé≠ ÂèØÁî®ËØ¥ËØù‰∫∫: {available_spks}")
        except Exception as e:
            print(f"‚ö†Ô∏è Ëé∑ÂèñËØ¥ËØù‰∫∫ÂàóË°®Â§±Ë¥•: {e}")

        if available_spks and speaker not in available_spks:
            speaker = available_spks[0] if available_spks else "‰∏≠ÊñáÂ•≥"
            print(f"üîÑ ÂàáÊç¢Âà∞ÂèØÁî®ËØ¥ËØù‰∫∫: {speaker}")
        else:
            print(f"üé≠ ‰ΩøÁî®ËØ¥ËØù‰∫∫: {speaker}")
        
        # Generate speech
        speech_data = None

        # Helper function for zero-shot inference
        def try_zero_shot_inference():
            # ‰ºòÂÖàÊü•ÊâæCosyVoiceÂéüÁîüassetÁõÆÂΩï‰∏ãÁöÑÈü≥È¢ëÊñá‰ª∂
            cosyvoice_asset_paths = [
                Path(__file__).parent / "CosyVoice" / "asset" / "zero_shot_prompt.wav",
                Path(__file__).parent / "CosyVoice" / "asset" / "samples" / "zero_shot_prompt.wav",
                Path(__file__).parent / "CosyVoice" / "asset" / "samples" / "cross_lingual_prompt.wav",
                Path(__file__).parent / "CosyVoice" / "asset" / "instruct_prompt.wav",
            ]

            # Ê¨°‰ºòÈÄâÊã©ÔºömodelsÁõÆÂΩïÂíåÂÖ∂‰ªñ‰ΩçÁΩÆ
            fallback_paths = [
                Path(__file__).parent / "models" / "cosyvoice" / "asset" / "zero_shot_prompt.wav",
                Path(__file__).parent / "CosyVoice" / "zero_shot_prompt.wav",
                Path(__file__).parent / "zero_shot_prompt.wav"
            ]

            # ÁªÑÂêàÊâÄÊúâË∑ØÂæÑÔºå‰ºòÂÖà‰ΩøÁî®ÂéüÁîüassetÊñá‰ª∂
            all_prompt_paths = cosyvoice_asset_paths + fallback_paths

            for path in all_prompt_paths:
                if path.exists():
                    try:
                        print(f"üéµ ÊâæÂà∞ÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂: {path}")
                        prompt_speech = load_wav(str(path), 16000)
                        return cosyvoice_model.inference_zero_shot(
                            request.input, "Â∏åÊúõ‰Ω†‰ª•ÂêéËÉΩÂ§üÂÅöÁöÑÊØîÊàëËøòÂ•ΩÂë¶„ÄÇ", prompt_speech,
                            stream=False, speed=request.speed
                        )
                    except Exception as e:
                        print(f"‚ö†Ô∏è Èõ∂Ê†∑Êú¨Ê®°ÂºèË∑ØÂæÑ {path} Â§±Ë¥•: {e}")
                        continue

            # Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞‰ªª‰ΩïÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂ÔºåÂ∞ùËØïÊó†ÊèêÁ§∫Êé®ÁêÜ
            print("üìù Êú™ÊâæÂà∞ÊèêÁ§∫Èü≥È¢ëÊñá‰ª∂ÔºåÂ∞ùËØï‰ΩøÁî®Á©∫ÊèêÁ§∫ËøõË°åÈõ∂Ê†∑Êú¨Êé®ÁêÜ")
            try:
                # Some CosyVoice2 models support inference without explicit prompt audio
                return cosyvoice_model.inference_zero_shot(
                    request.input, "Â∏åÊúõ‰Ω†‰ª•ÂêéËÉΩÂ§üÂÅöÁöÑÊØîÊàëËøòÂ•ΩÂë¶„ÄÇ", None,
                    stream=False, speed=request.speed
                )
            except Exception as e:
                print(f"‚ö†Ô∏è Êó†ÊèêÁ§∫Èü≥È¢ëÈõ∂Ê†∑Êú¨Êé®ÁêÜÂ§±Ë¥•: {e}")
                return None

        # Try different inference methods based on what's available
        # For CosyVoice2-0.5B, prioritize cross_lingual and instruct modes
        inference_methods = [
            ('inference_sft', lambda: cosyvoice_model.inference_sft(request.input, speaker, stream=False, speed=request.speed) if available_spks else None),
            ('inference_cross_lingual', lambda: cosyvoice_model.inference_cross_lingual(request.input, None, stream=False) if hasattr(cosyvoice_model, 'inference_cross_lingual') else None),
            ('inference_instruct2', lambda: cosyvoice_model.inference_instruct2(request.input, 'Áî®Ëá™ÁÑ∂ÁöÑËØ≠Ë∞ÉËØ¥ËøôÂè•ËØù', None, stream=False) if hasattr(cosyvoice_model, 'inference_instruct2') else None),
            ('inference_zero_shot', try_zero_shot_inference),
            ('inference', lambda: cosyvoice_model.inference(request.input, stream=False, speed=request.speed)),
            ('tts', lambda: cosyvoice_model.tts(request.input, speaker=speaker)),
            ('generate', lambda: cosyvoice_model.generate(request.input)),
        ]

        for method_name, method_func in inference_methods:
            if hasattr(cosyvoice_model, method_name) and speech_data is None:
                try:
                    print(f"üé§ Â∞ùËØï {method_name} Ê®°ÂºèÁîüÊàêËØ≠Èü≥...")

                    # Skip methods that require unavailable resources
                    if method_name == 'inference_sft' and not available_spks:
                        print(f"‚è≠Ô∏è Ë∑≥Ëøá {method_name}ÔºöÊó†ÂèØÁî®ËØ¥ËØù‰∫∫")
                        continue

                    if method_name in ['inference_cross_lingual', 'inference_instruct2'] and not hasattr(cosyvoice_model, method_name):
                        print(f"‚è≠Ô∏è Ë∑≥Ëøá {method_name}ÔºöÊñπÊ≥ï‰∏çÂèØÁî®")
                        continue

                    result = method_func()
                    if result is None:
                        continue

                    # Handle different result formats
                    if hasattr(result, '__iter__') and not isinstance(result, (str, bytes)):
                        for i, output in enumerate(result):
                            if isinstance(output, dict) and 'tts_speech' in output:
                                speech_data = output['tts_speech']
                                break
                            elif hasattr(output, 'audio') or hasattr(output, 'speech'):
                                speech_data = getattr(output, 'audio', getattr(output, 'speech', None))
                                break
                            elif isinstance(output, torch.Tensor):
                                speech_data = output
                                break
                    elif isinstance(result, torch.Tensor):
                        speech_data = result
                    elif isinstance(result, dict) and 'tts_speech' in result:
                        speech_data = result['tts_speech']

                    if speech_data is not None:
                        print(f"‚úÖ {method_name} Ê®°ÂºèÁîüÊàêÊàêÂäü")
                        break

                except Exception as e:
                    print(f"‚ö†Ô∏è {method_name} Ê®°ÂºèÂ§±Ë¥•: {e}")
                    continue
        
        if speech_data is None:
            raise HTTPException(status_code=500, detail="Failed to generate speech")
        
        # Convert to numpy and save as wav
        audio_numpy = speech_data.cpu().numpy().flatten()
        
        # Create temporary file for audio conversion
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            torchaudio.save(tmp_file.name, speech_data, cosyvoice_model.sample_rate)
            
            # Read the audio file
            with open(tmp_file.name, "rb") as f:
                audio_bytes = f.read()
            
            # Clean up temp file
            os.unlink(tmp_file.name)
        
        # Return appropriate format
        if request.response_format == "mp3":
            # For simplicity, return WAV with MP3 content-type
            # In production, you'd want to convert to actual MP3
            return Response(content=audio_bytes, media_type="audio/mpeg")
        elif request.response_format == "wav":
            return Response(content=audio_bytes, media_type="audio/wav")
        else:
            return Response(content=audio_bytes, media_type="audio/wav")
            
    except Exception as e:
        print(f"TTS Error: {e}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Speech generation failed: {str(e)}")

@app.post("/v1/audio/transcriptions", response_model=TranscriptionResponse)
async def create_transcription(
    file: UploadFile = File(...),
    model: str = Form("whisper-1"),
    language: Optional[str] = Form(None),
    prompt: Optional[str] = Form(None),
    response_format: str = Form("json"),
    temperature: float = Form(0.0)
):
    """
    Transcribe audio to text using FunASR
    Compatible with OpenAI's /v1/audio/transcriptions endpoint
    """
    tts_only_mode = globals().get('TTS_ONLY_MODE', False)
    if tts_only_mode:
        raise HTTPException(status_code=503, detail="ASR functionality disabled in TTS-only mode")

    if funasr_model is None:
        raise HTTPException(status_code=503, detail="FunASR model not available")

    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # Use FunASR for transcription
            result = funasr_model(tmp_file_path)

            # Clean up temp file
            os.unlink(tmp_file_path)

            # Extract text from result
            if hasattr(result, 'text'):
                text = result.text
            elif isinstance(result, list) and len(result) > 0:
                # Handle list output
                text = ""
                for item in result:
                    if hasattr(item, 'text'):
                        text += item.text
                    elif isinstance(item, dict) and 'text' in item:
                        text += item['text']
                    elif isinstance(item, str):
                        text += item
            elif isinstance(result, dict) and 'text' in result:
                text = result['text']
            else:
                text = str(result)

            return TranscriptionResponse(text=text.strip())

        except Exception as e:
            # Clean up temp file on error
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)
            raise e

    except Exception as e:
        print(f"Transcription Error: {e}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Transcription failed: {str(e)}")

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "cosyvoice_available": cosyvoice_model is not None,
        "funasr_available": funasr_model is not None
    }

@app.get("/v1/models")
async def list_models():
    """List available models (OpenAI compatible)"""
    models = []
    
    if cosyvoice_model is not None:
        models.extend([
            {"id": "tts-1", "object": "model", "created": 1677610602, "owned_by": "cosyvoice"},
            {"id": "tts-1-hd", "object": "model", "created": 1677610602, "owned_by": "cosyvoice"}
        ])
    
    if funasr_model is not None:
        models.extend([
            {"id": "whisper-1", "object": "model", "created": 1677610602, "owned_by": "funasr"}
        ])
    
    return {"object": "list", "data": models}

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind to") 
    parser.add_argument("--cosyvoice-model", type=str, 
                       default="models/cosyvoice/CosyVoice2-0.5B",
                       help="CosyVoice model path (now defaults to models directory)")
    parser.add_argument("--asr-model", type=str, default="paraformer-zh",
                       help="FunASR model name (paraformer-zh, paraformer-zh-streaming)")
    parser.add_argument("--fast", action="store_true",
                       help="Use faster/smaller models for demo (enables TTS-only mode)")
    parser.add_argument("--tts-only", action="store_true",
                       help="TTS-only mode: only enable text-to-speech, skip ASR for fastest startup")

    args = parser.parse_args()

    # Apply fast mode
    if args.fast:
        args.tts_only = True
        print("üöÄ Âø´ÈÄüÊ®°ÂºèÂ∑≤ÂêØÁî®Ôºå‰ΩøÁî®TTS‰∏ìÁî®Ê®°Âºè")

    # Apply TTS-only mode
    if args.tts_only:
        globals()['TTS_ONLY_MODE'] = True
        print("üéôÔ∏è TTS‰∏ìÁî®Ê®°ÂºèÂ∑≤ÂêØÁî®ÔºåÂ∞ÜË∑≥ËøáASRÊ®°ÂûãÂä†ËΩΩ")
    else:
        globals()['TTS_ONLY_MODE'] = False
    
    # Override defaults
    globals()['COSYVOICE_MODEL_PATH'] = args.cosyvoice_model
    globals()['ASR_MODEL_NAME'] = args.asr_model

    print(f"Starting OpenAI-compatible API server on {args.host}:{args.port}")
    print(f"CosyVoice model: {args.cosyvoice_model}")
    if not args.tts_only:
        print(f"FunASR model: {args.asr_model}")
    else:
        print("ASR model: Â∑≤Á¶ÅÁî® (TTS‰∏ìÁî®Ê®°Âºè)")
    
    uvicorn.run(app, host=args.host, port=args.port)